\section{Responsible Research} \label{section:responsible_research}
In algorithmic optimization for NP-hard problems, the impossibility of brute-force methods on large problem instances results in researchers competing to improve the current state-of-the-art solutions. Because research is mostly focused on positive results several criteria for optimizing the state-of-the-art are often overlooked or ignored. The result is research papers that look like they indicate more optimal algorithms have been found whereas the truth of the improvement might come from a different place altogether.

When technology evolves a lot of variables involved in algorithm testing are also improving, even without directly being a part of the algorithm. Examples are newer hardware, better compilers, improved coding skills and programming language differences. If a new algorithm is tested and these variables are not kept the same or the old versions are retested with the same new variables the resulting improvement might not be a result of a more optimal algorithm. Additionally, these variables do not cancel each other out. Over time it is to be expected that all the example variables are resulting in better performance as time passes.

To compare the performance of algorithms in a fair way some rules to keep variables equal are required. In this project the following rules have been set to keep the results fairer in comparison: 
\begin{itemize}
\item Each algorithm is implemented in the same coding language
\item The algorithms are implemented by the same researcher to ensure the coding skill is consistent
\item Every algorithm is run on the same hardware
\item Compiler and operating system are equal for all algorithms
\item As a stopping criterion the CPU time is used
\end{itemize}
To make sure these rules can also be adhered to in the future the source code is provided to test the algorithms on newer hardware when it is released. Other researchers are also encouraged to implement the described algorithms for themselves and set up the experiments alongside their algorithms.


%Reflect on the ethical aspects of your research and discuss the reproducibility of your methods. Note that although in many published works there is no such a section (it may be part of some meta-information collected by the journal, or part of the discussion section), we require you to think (and report) about this as part of this course.